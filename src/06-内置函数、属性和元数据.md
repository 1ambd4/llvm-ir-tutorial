# 内置函数、属性和元数据

在LLVM IR中，除了基础的数据表示、控制流之外，还有内置函数、属性和元数据等，能够影响二进制程序生成的功能。

## 内置函数

我们回顾一下，LLVM IR的作用实际上是将编译器前端与后端解耦合。编程语言的前端开发者，负责将输入的编程语言代码进行解析，生成LLVM IR；指令集架构的后端开发者，负责将输入的LLVM IR生成为目标架构的二进制指令。因此，LLVM IR提供了若干非常基础的指令，如`add`、`br`、`call`等。这样做的好处在于：

* 对前端开发者而言，这些指令语义足够全，使用方法也和常见高级语言类似。
* 对后端开发者而言，这些指令相对数目比较少，提供的功能也相对较为独立，在大部分常见的指令集中都有类似的指令与其对应。

但是，这样的策略也有其弊端：

* 对前端开发者而言，仍然有部分通用的语义无法被单个指令所涵盖
* 对后端开发者而言，对一些通用指令的优化无法针对LLVM IR指令来做

### `memcpy`

以内存拷贝为例。熟悉AMD64或者AArch64的开发者一定知道，在这些支持向量操作的指令集架构中，大规模的内存拷贝往往是通过向量指令来实现的，Glibc中的`memcpy`就是这样实现的。

但是对于通用编程语言来说，标准库往往不喜欢直接调用libc中的函数，会产生一些不必要的依赖。并且，`memcpy`用向量操作来实现已经是一个非常通用的方案了，所以能不能复用一些逻辑呢？

对于此类，LLVM IR指令过于基础，但是却非常广泛地使用同一套实现逻辑的情况，LLVM IR提供了「[内置函数](https://llvm.org/docs/LangRef.html#intrinsic-functions)」（Intrinsic Functions）功能来解决。

所谓内置函数，我们可以理解成一些可以像普通的LLVM IR函数一样调用的函数，但这些函数不需要开发者自己实现，LLVM的后端开发者提供了这些函数的实现。

例如，LLVM IR提供了[`llvm.memcpy`](https://llvm.org/docs/LangRef.html#llvm-memcpy-intrinsic)内置函数，以提供内存的拷贝操作。前端开发者只需要调用这个函数，就可以实现内存拷贝功能了。

我们熟知的Rust语言，在利用LLVM生成二进制程序时，就是使用的这个函数，可以参考其封装的[`LLVMRustBuildMemCpy`](https://github.com/rust-lang/rust/blob/90c541806f23a127002de5b4038be731ba1458ca/compiler/rustc_llvm/llvm-wrapper/RustWrapper.cpp#L1448-L1456)与调用者[`memcpy`](https://github.com/rust-lang/rust/blob/90c541806f23a127002de5b4038be731ba1458ca/compiler/rustc_codegen_llvm/src/builder.rs#L871-L896)。

### 静态分支预测

LLVM IR提供的内置函数有许多，这里，我们再以静态分支预测为例，介绍一个常见内置函数。

我们在阅读一些大规模项目源码时，例如Linux内核源码、QEMU源码等，往往会注意到大量使用的`likely`与`unlikely`，如：

```c
if (likely(x > 0)) {
    // Do something
}
```

这个`likely`是什么？它是干什么用的？事实上，`likely`与`unlikely`往往是通过宏定义实现的，它们的作用是静态分支预测。

我们知道，对于C语言等常见的编程语言的`if`语句，在生成二进制程序的时候，我们可以交换它的两个分支的位置。紧接着`cmp`等判断语句的分支，在执行时，不会发生跳转，而另一个分支则需要设置PC寄存器来跳转。这种跳转往往会造成一定程度的性能损耗，这些具体的我在「[在 Apple Silicon Mac 上入门汇编语言](https://github.com/Evian-Zhang/learn-assembly-on-Apple-Silicon-Mac)」中的[编译期分支预测](https://evian-zhang.github.io/learn-assembly-on-Apple-Silicon-Mac/11-跳转.html#编译期分支预测)一节中有详细阐述。总之，我们需要给编译器一些信息，来排布不同的分支布局。

对于Clang来说，这是通过[内置`expect`指令](https://llvm.org/docs/BranchWeightMetadata.html#built-in-expect-instructions)来实现的，也就是说：

```c
#define likely(x)       __builtin_expect(!!(x), 1)
#define unlikely(x)     __builtin_expect(!!(x), 0)
```

而`__builtin_expect`这个内置指令，就会翻译为LLVM IR中的[`llvm.expect`](https://llvm.org/docs/LangRef.html#llvm-expect-intrinsic)内置函数，从而实现了静态分支预测。

## 属性

在C语言中，我们会遇到一个函数的修饰符：`inline`。这个修饰符会提示编译器，建议编译器在遇到这个函数的调用时，内联这个函数。这类的信息，LLVM会将其看作函数的「[属性](https://llvm.org/docs/LangRef.html#function-attributes)」（Attribtues）。

在之前，我们也提到过，我们可以：

```llvm
define void @foo() attr1 attr2 attr3 {
    ; ...
}
```

如果有多个函数有相同的属性，我们可以用一个属性组的形式来复用：

```llvm
define void @foo1() #0 {
    ; ...
}
define void @foo2() #0 {
    ; ...
}
attributes #0 = { attr1 attr2 attr3 }
```

LLVM支持的函数属性有多种，我们来看看几个比较容易理解的，由函数属性控制的优化：

### 内联

函数内联是一个非常复杂的概念，这里我们只是简单地来看一下，下面这个C语言代码：

```c
inline int foo(int a) __attribute__((always_inline));

int foo(int a) {
    if (a > 0) {
        return a;
    } else {
        return 0;
    }
}
```

这里声明了`foo`函数，并且用了一个扩展语法`__attribute__((always_inline))`，这个语法实际上的作用就是给函数加上`alwaysinline`的属性。

我们查看其生成的LLVM IR：

```llvm
define dso_local i32 @foo(i32 noundef %0) #0 {
  ; ...
}

attributes #0 = { alwaysinline nounwind uwtable "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
```

可以看到，其确实有了`alwaysinline`这个属性。

### 帧指针清除优化

我们再来看一个属性控制的优化：帧指针清除优化（Frame Pointer Elimination）。

在讲这个之前，先讲一个比较小的优化。我们将一个非常简单的C程序

```c
void foo(int a, int b) {}
int main() {
    foo(1, 2);
    return 0;
}
```

编译为汇编程序，可以发现，`foo`函数的汇编代码为：

```x86asm
foo:
    pushq   %rbp
    movq    %rsp, %rbp
    movl    %edi, -4(%rbp)
    movl    %esi, -8(%rbp)
    popq    %rbp
```

与我们常识有些违背。为啥这里栈不先增加（也就是对`rsp`寄存器进行`sub`），就直接把`edi`, `esi`的值移入栈内了呢？`-4(%rbp)`和`-8(%rbp)`的内存空间此刻似乎并不属于栈。

这是因为，在System V关于amd64架构的标准中，规定了`rsp`以下128个字节为red zone。这个区域，信号和异常处理函数均不会使用。因此，一个函数可以放心使用`rsp`以下128个字节的内容。

同时，我们对栈指针进行操作，一个很重要的原因就是为了进一步函数调用的时候，使用`call`指令会自动将被调用函数的返回地址压栈，那么就需要在调用`call`指令之前，保证栈顶指针确实指向栈顶，否则压栈就会覆盖一些数据。

但此时，我们的`foo`函数并没有调用别的函数，也就不会产生压栈行为。因此，如果在栈帧不超过128个字节的情况下，编译器自动为我们省去了这样的操作。为了验证这一点，我们做一个小的修改：

```c
void bar() {}
void foo(int a, int b) { bar(); }
int main() {
    foo(1, 2);
    return 0;
}
```

这时，我们再看编译出的`foo`函数的汇编代码：

```x86asm
foo:
    pushq   %rbp
    movq    %rsp, %rbp
    subq    $16, %rsp
    movl    %edi, -4(%rbp)
    movl    %esi, -8(%rbp)
    callq   bar
    addq    $16, %rsp
    popq    %rbp
    retq
```

确实增加了对`rbp`的`sub`和`add`操作。而此时的`bar`函数，也没有对`rsp`的操作。

接下来，就要讲帧指针清除优化了。经过我们上述的讨论，一个函数在进入时会有一些固定动作：

1. 把`rbp`压栈
2. 把`rsp`放入`rbp`
3. 减`rsp`，预留栈空间

在函数返回之前，也有其相应的操作：

1. 加`rsp`，回收栈空间
2. 把`rbp`最初的值弹栈回到`rbp`

我们刚刚讲的优化，使得没有调用别的函数的函数，可以省略掉进入时的第3步和返回前的第1步。那么，是否还可以继续省略呢？

那么，我们就要考虑为什么需要这些步骤。这些步骤都是围绕`rbp`进行的，而正是因为`rbp`经常进行这种操作，所以我们把`rbp`称为帧指针。之所以要进行这些操作，是因为我们在函数执行的过程中，栈顶指针随着不断调用别的函数，会不断移动，导致我们根据栈顶指针的位置，不太方便确定局部变量的位置。而如果我们在一开始就把`rsp`的值放在`rbp`中，那么局部变量的位置相对`rbp`是固定的，就更好确认了。注意到我们这里说根据`rsp`的值确认局部变量的位置只是不方便，但并不是不能做到。所以，我们可以增加一些编译器的负担，而把帧指针清除。

帧指针清除在LLVM IR层面其实十分方便，就是什么都不写。我们可以观察

```llvm
define void @foo(i32 %a, i32 %b) {
    %1 = alloca i32
    %2 = alloca i32
    store i32 %a, ptr %1
    store i32 %b, ptr %2
    ret void
}
```

这个函数在编译成汇编语言之后，是：

```x86asm
foo:
    movl    %edi, -4(%rsp)
    movl    %esi, -8(%rsp)
    retq
```

不仅没有了栈的增加减少（之前提过的优化），也没有了对`rbp`的操作（帧指针清除）。

要想恢复这一操作也十分简单，在函数参数列表后加上一个属性`"frame-pointer"="all"`：

```llvm
define void @foo(i32 %a, i32 %b) "frame-pointer"="all" {
    %1 = alloca i32
    %2 = alloca i32
    store i32 %a, ptr %1
    store i32 %b, ptr %2
    ret void
}
```

其编译后的汇编程序就是：

```x86asm
foo:
    pushq   %rbp
    movq    %rsp, %rbp
    movl    %edi, -4(%rbp)
    movl    %esi, -8(%rbp)
    popq    %rbp
    retq
```

恢复了往日的雄风。
